package storage

import (
	"bytes"
	"context"
	"fmt"
	"io"
	"log/slog"
	"runtime"
	"sort"
	"sync"
	"time"

	"github.com/aws/aws-sdk-go-v2/aws"
	"github.com/aws/aws-sdk-go-v2/config"
	"github.com/aws/aws-sdk-go-v2/credentials"
	"github.com/aws/aws-sdk-go-v2/service/s3"
	"golang.org/x/sync/errgroup"
	"google.golang.org/protobuf/encoding/protojson"

	"github.com/jh125486/gradebot/pkg/contextlog"
	"github.com/jh125486/gradebot/pkg/proto"
)

// R2Config holds R2/S3 storage configuration
type R2Config struct {
	// For production R2/Cloudflare
	Endpoint string
	Region   string
	Bucket   string

	// Credentials
	AccessKeyID     string
	SecretAccessKey string

	// Addressing style
	UsePathStyle bool
}

const (
	submissionKeyFormat = "submissions/%s.json"
)

// R2Storage implements Storage using Cloudflare R2 (S3-compatible)
type R2Storage struct {
	maxConcurrentFetches int
	client               *s3.Client
	bucket               string
}

// This formula allows efficient concurrent object fetches without overwhelming the system,
// providing approximately 4 concurrent requests per available CPU core.
const maxConcurrentMultiplier = 4

// NewR2Storage creates a new R2 storage instance
func NewR2Storage(ctx context.Context, cfg *R2Config) (*R2Storage, error) {
	// Apply defaults
	if cfg.Bucket == "" {
		cfg.Bucket = "gradebot-storage"
	}
	if cfg.Region == "" {
		cfg.Region = "auto"
	}
	// Determine region based on addressing style
	region := cfg.Region
	if cfg.UsePathStyle {
		// LocalStack typically uses us-east-1
		region = "us-east-1"
	}

	if cfg.UsePathStyle {
		contextlog.From(ctx).InfoContext(ctx, "Using path-style addressing for storage",
			slog.String("endpoint", cfg.Endpoint),
			slog.String("region", region),
		)
	} else {
		contextlog.From(ctx).InfoContext(ctx, "Using virtual-hosted addressing for storage",
			slog.String("endpoint", cfg.Endpoint),
			slog.String("region", region),
		)
	}

	awsCfg, err := config.LoadDefaultConfig(ctx,
		config.WithRegion(region),
		config.WithCredentialsProvider(credentials.NewStaticCredentialsProvider(
			cfg.AccessKeyID,
			cfg.SecretAccessKey,
			"",
		)),
	)
	if err != nil {
		return nil, fmt.Errorf("failed to load AWS config: %w", err)
	}

	client := s3.NewFromConfig(awsCfg, func(o *s3.Options) {
		o.UsePathStyle = cfg.UsePathStyle
		o.BaseEndpoint = &cfg.Endpoint
	})

	storage := &R2Storage{
		maxConcurrentFetches: maxConcurrentMultiplier * runtime.NumCPU(),
		client:               client,
		bucket:               cfg.Bucket,
	}

	// Ensure bucket exists, create if it doesn't
	if err := storage.ensureBucketExists(ctx); err != nil {
		return nil, fmt.Errorf("failed to ensure bucket exists: %w", err)
	}

	return storage, nil
}

// SaveResult saves a rubric result to storage
func (r *R2Storage) SaveResult(ctx context.Context, result *proto.Result) error {
	if result == nil {
		return fmt.Errorf("result cannot be nil")
	}
	if result.SubmissionId == "" {
		return fmt.Errorf("submission ID is required")
	}

	start := time.Now()
	marshaler := protojson.MarshalOptions{
		UseProtoNames:   true,
		EmitUnpopulated: true,
	}
	data, err := marshaler.Marshal(result)
	if err != nil {
		return fmt.Errorf("failed to marshal result: %w", err)
	}

	key := fmt.Sprintf(submissionKeyFormat, result.SubmissionId)

	_, err = r.client.PutObject(ctx, &s3.PutObjectInput{
		Bucket:      &r.bucket,
		Key:         &key,
		Body:        bytes.NewReader(data),
		ContentType: aws.String("application/json"),
	})
	if err != nil {
		return fmt.Errorf("failed to save result to R2: %w", err)
	}

	contextlog.From(ctx).InfoContext(ctx, "Saved rubric result",
		slog.String("submission_id", result.SubmissionId),
		slog.String("bucket", r.bucket),
		slog.Duration("duration", time.Since(start)),
	)

	return nil
}

// LoadResult loads a rubric result from storage
func (r *R2Storage) LoadResult(ctx context.Context, submissionID string) (*proto.Result, error) {
	start := time.Now()
	key := fmt.Sprintf(submissionKeyFormat, submissionID)

	resp, err := r.client.GetObject(ctx, &s3.GetObjectInput{
		Bucket: &r.bucket,
		Key:    &key,
	})
	if err != nil {
		return nil, fmt.Errorf("failed to load result from R2: %w", err)
	}
	defer resp.Body.Close()

	data, err := io.ReadAll(resp.Body)
	if err != nil {
		return nil, fmt.Errorf("failed to read response body: %w", err)
	}

	var result proto.Result
	unmarshaler := protojson.UnmarshalOptions{
		DiscardUnknown: true,
	}
	if err := unmarshaler.Unmarshal(data, &result); err != nil {
		return nil, fmt.Errorf("failed to decode result: %w", err)
	}
	contextlog.From(ctx).InfoContext(ctx, "Loaded rubric result",
		slog.String("submission_id", submissionID),
		slog.String("bucket", r.bucket),
		slog.Duration("duration", time.Since(start)),
	)

	return &result, nil
}

// collectAllKeys retrieves all submission object keys from storage
func (r *R2Storage) collectAllKeys(ctx context.Context) ([]string, error) {
	var allKeys []string
	paginator := s3.NewListObjectsV2Paginator(r.client, &s3.ListObjectsV2Input{
		Bucket: &r.bucket,
		Prefix: aws.String("submissions/"),
	})

	for paginator.HasMorePages() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, fmt.Errorf("failed to list objects: %w", err)
		}

		for _, obj := range page.Contents {
			if obj.Key == nil {
				continue
			}

			key := *obj.Key
			if len(key) < 13 || key[len(key)-5:] != ".json" {
				continue
			}

			allKeys = append(allKeys, key)
		}
	}

	return allKeys, nil
}

// ListResultsPaginated fetches a paginated list of results from storage
func (r *R2Storage) ListResultsPaginated(ctx context.Context, params ListResultsParams) (
	results map[string]*proto.Result, totalCount int, err error) {
	start := time.Now()

	if params.Page < 1 {
		params.Page = 1
	}
	if params.PageSize < 1 || params.PageSize > 1000 {
		params.PageSize = 20 // Default
	}

	// Collect all keys from storage
	allKeys, err := r.collectAllKeys(ctx)
	if err != nil {
		return nil, 0, err
	}

	// Load all results to filter by project if needed
	var filteredKeys []string
	if params.Project != "" {
		// Need to load results to filter by project
		allResults := r.loadResultsParallel(ctx, allKeys)
		for key, result := range allResults {
			if result.Project == params.Project {
				filteredKeys = append(filteredKeys, fmt.Sprintf(submissionKeyFormat, key))
			}
		}
	} else {
		filteredKeys = allKeys
	}

	totalCount = len(filteredKeys)

	// Calculate pagination boundaries
	startIdx, endIdx := params.CalculatePaginationBounds(totalCount)

	// Fetch results for this page in parallel
	pageKeys := filteredKeys[startIdx:endIdx]
	results = r.loadResultsParallel(ctx, pageKeys)

	contextlog.From(ctx).InfoContext(ctx, "Listed paginated rubric results",
		slog.Int("page", params.Page),
		slog.Int("page_size", params.PageSize),
		slog.String("project", params.Project),
		slog.Int("total_count", totalCount),
		slog.Int("returned", len(results)),
		slog.String("bucket", r.bucket),
		slog.Duration("duration", time.Since(start)),
	)

	return results, totalCount, nil
}

// loadResultsParallel fetches multiple results concurrently using errgroup
func (r *R2Storage) loadResultsParallel(ctx context.Context, keys []string) map[string]*proto.Result {
	results := make(map[string]*proto.Result)
	var mu sync.Mutex

	// Create errgroup with context for better error handling and context cancellation
	wg, ctx := errgroup.WithContext(ctx)
	wg.SetLimit(r.maxConcurrentFetches)

	for _, key := range keys {
		wg.Go(func() error {
			submissionID := key[12 : len(key)-5] // Remove "submissions/" prefix and ".json" suffix
			result, err := r.LoadResult(ctx, submissionID)
			if err != nil {
				contextlog.From(ctx).WarnContext(ctx, "Failed to load result",
					slog.String("submission_id", submissionID),
					slog.Any("error", err),
				)
				return nil // Don't fail entire batch on single error
			}

			mu.Lock()
			results[submissionID] = result
			mu.Unlock()

			return nil
		})
	}

	// Wait for all goroutines to complete
	if err := wg.Wait(); err != nil {
		contextlog.From(ctx).ErrorContext(ctx, "Error loading results in parallel", slog.Any("error", err))
	}

	return results
}

// ensureBucketExists checks if the bucket exists and creates it if it doesn't
func (r *R2Storage) ensureBucketExists(ctx context.Context) error {
	// Try to check if bucket exists by listing objects (HeadBucket might not work with all S3-compatible services)
	_, err := r.client.ListObjectsV2(ctx, &s3.ListObjectsV2Input{
		Bucket:  &r.bucket,
		MaxKeys: aws.Int32(1), // Just check if we can access the bucket
	})
	if err != nil {
		// If bucket doesn't exist, try to create it
		contextlog.From(ctx).InfoContext(ctx, "Bucket does not exist, attempting to create", slog.String("bucket", r.bucket))

		_, createErr := r.client.CreateBucket(ctx, &s3.CreateBucketInput{
			Bucket: &r.bucket,
		})

		if createErr != nil {
			return fmt.Errorf("failed to create bucket %s: %w", r.bucket, createErr)
		}

		contextlog.From(ctx).InfoContext(ctx, "Successfully created bucket", slog.String("bucket", r.bucket))
		return nil
	}

	contextlog.From(ctx).InfoContext(ctx, "Bucket already exists", slog.String("bucket", r.bucket))
	return nil
}

// ListProjects returns a list of distinct project names from storage
func (r *R2Storage) ListProjects(ctx context.Context) ([]string, error) {
	start := time.Now()

	// Collect all keys from storage
	allKeys, err := r.collectAllKeys(ctx)
	if err != nil {
		return nil, err
	}

	// Load all results to extract unique projects
	allResults := r.loadResultsParallel(ctx, allKeys)

	projectSet := make(map[string]bool)
	for _, result := range allResults {
		if result.Project != "" {
			projectSet[result.Project] = true
		}
	}

	// Convert set to sorted slice
	projects := make([]string, 0, len(projectSet))
	for project := range projectSet {
		projects = append(projects, project)
	}
	sort.Strings(projects)

	contextlog.From(ctx).InfoContext(ctx, "Listed projects",
		slog.Int("count", len(projects)),
		slog.String("bucket", r.bucket),
		slog.Duration("duration", time.Since(start)),
	)

	return projects, nil
}

// Close closes the storage connection (no-op for R2/S3)
func (r *R2Storage) Close() error {
	return nil
}
